作业
1.
1)relu变体
2)其他激活函数还有哪些
2.backward(反向传播） coding
3.大作业：NumPy实现一个2层的神经网络，在MINIST上达到85%+的准确率
看李沐老师